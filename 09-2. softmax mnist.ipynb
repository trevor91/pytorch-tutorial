{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(root = './mnist_data/',\n",
    "                              train = True,\n",
    "                              transform = transforms.ToTensor(),\n",
    "                              download = True)\n",
    "test_dataset = datasets.MNIST(root = './mnist_data/',\n",
    "                             train = False,\n",
    "                             transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                         batch_size = batch_size,\n",
    "                                         shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(784, 520)\n",
    "        self.l2 = nn.Linear(520, 320)\n",
    "        self.l3 = nn.Linear(320, 240)\n",
    "        self.l4 = nn.Linear(240, 120)\n",
    "        self.l5 = nn.Linear(120, 10)\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1,784)\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return(self.l5(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print(\"train epoch: {} [{}/{} ({:.0f}%)]\\tLoss:{:.6f}\".format(\n",
    "                                epoch,\n",
    "                                    batch_idx * len(data),\n",
    "                                       len(train_loader.dataset),\n",
    "                                            100.*batch_idx/len(train_loader),\n",
    "                                                            loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile= True), Variable(target)\n",
    "        output = model(data)\n",
    "        \n",
    "        test_loss += criterion(output,target).data[0]\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\ntest set: Average loss: {:.4f}, accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                                     test_loss,\n",
    "                                                       correct,\n",
    "                                                          len(test_loader.dataset),\n",
    "                                                              100.*correct/len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 1 [0/60000 (0%)]\tLoss:2.308292\n",
      "train epoch: 1 [640/60000 (1%)]\tLoss:2.303755\n",
      "train epoch: 1 [1280/60000 (2%)]\tLoss:2.298727\n",
      "train epoch: 1 [1920/60000 (3%)]\tLoss:2.305094\n",
      "train epoch: 1 [2560/60000 (4%)]\tLoss:2.302696\n",
      "train epoch: 1 [3200/60000 (5%)]\tLoss:2.301525\n",
      "train epoch: 1 [3840/60000 (6%)]\tLoss:2.298875\n",
      "train epoch: 1 [4480/60000 (7%)]\tLoss:2.296927\n",
      "train epoch: 1 [5120/60000 (9%)]\tLoss:2.302556\n",
      "train epoch: 1 [5760/60000 (10%)]\tLoss:2.297794\n",
      "train epoch: 1 [6400/60000 (11%)]\tLoss:2.301883\n",
      "train epoch: 1 [7040/60000 (12%)]\tLoss:2.307085\n",
      "train epoch: 1 [7680/60000 (13%)]\tLoss:2.299423\n",
      "train epoch: 1 [8320/60000 (14%)]\tLoss:2.302074\n",
      "train epoch: 1 [8960/60000 (15%)]\tLoss:2.296047\n",
      "train epoch: 1 [9600/60000 (16%)]\tLoss:2.292809\n",
      "train epoch: 1 [10240/60000 (17%)]\tLoss:2.299981\n",
      "train epoch: 1 [10880/60000 (18%)]\tLoss:2.298770\n",
      "train epoch: 1 [11520/60000 (19%)]\tLoss:2.288142\n",
      "train epoch: 1 [12160/60000 (20%)]\tLoss:2.298542\n",
      "train epoch: 1 [12800/60000 (21%)]\tLoss:2.300346\n",
      "train epoch: 1 [13440/60000 (22%)]\tLoss:2.294810\n",
      "train epoch: 1 [14080/60000 (23%)]\tLoss:2.292862\n",
      "train epoch: 1 [14720/60000 (25%)]\tLoss:2.293339\n",
      "train epoch: 1 [15360/60000 (26%)]\tLoss:2.291998\n",
      "train epoch: 1 [16000/60000 (27%)]\tLoss:2.294640\n",
      "train epoch: 1 [16640/60000 (28%)]\tLoss:2.293292\n",
      "train epoch: 1 [17280/60000 (29%)]\tLoss:2.287698\n",
      "train epoch: 1 [17920/60000 (30%)]\tLoss:2.295264\n",
      "train epoch: 1 [18560/60000 (31%)]\tLoss:2.292224\n",
      "train epoch: 1 [19200/60000 (32%)]\tLoss:2.281333\n",
      "train epoch: 1 [19840/60000 (33%)]\tLoss:2.290949\n",
      "train epoch: 1 [20480/60000 (34%)]\tLoss:2.291412\n",
      "train epoch: 1 [21120/60000 (35%)]\tLoss:2.285897\n",
      "train epoch: 1 [21760/60000 (36%)]\tLoss:2.286928\n",
      "train epoch: 1 [22400/60000 (37%)]\tLoss:2.285338\n",
      "train epoch: 1 [23040/60000 (38%)]\tLoss:2.280481\n",
      "train epoch: 1 [23680/60000 (39%)]\tLoss:2.285277\n",
      "train epoch: 1 [24320/60000 (41%)]\tLoss:2.292711\n",
      "train epoch: 1 [24960/60000 (42%)]\tLoss:2.283722\n",
      "train epoch: 1 [25600/60000 (43%)]\tLoss:2.277402\n",
      "train epoch: 1 [26240/60000 (44%)]\tLoss:2.277454\n",
      "train epoch: 1 [26880/60000 (45%)]\tLoss:2.270290\n",
      "train epoch: 1 [27520/60000 (46%)]\tLoss:2.277851\n",
      "train epoch: 1 [28160/60000 (47%)]\tLoss:2.276629\n",
      "train epoch: 1 [28800/60000 (48%)]\tLoss:2.280923\n",
      "train epoch: 1 [29440/60000 (49%)]\tLoss:2.276004\n",
      "train epoch: 1 [30080/60000 (50%)]\tLoss:2.280363\n",
      "train epoch: 1 [30720/60000 (51%)]\tLoss:2.274243\n",
      "train epoch: 1 [31360/60000 (52%)]\tLoss:2.271824\n",
      "train epoch: 1 [32000/60000 (53%)]\tLoss:2.275129\n",
      "train epoch: 1 [32640/60000 (54%)]\tLoss:2.278054\n",
      "train epoch: 1 [33280/60000 (55%)]\tLoss:2.274400\n",
      "train epoch: 1 [33920/60000 (57%)]\tLoss:2.278684\n",
      "train epoch: 1 [34560/60000 (58%)]\tLoss:2.274993\n",
      "train epoch: 1 [35200/60000 (59%)]\tLoss:2.258301\n",
      "train epoch: 1 [35840/60000 (60%)]\tLoss:2.267344\n",
      "train epoch: 1 [36480/60000 (61%)]\tLoss:2.254837\n",
      "train epoch: 1 [37120/60000 (62%)]\tLoss:2.249861\n",
      "train epoch: 1 [37760/60000 (63%)]\tLoss:2.264594\n",
      "train epoch: 1 [38400/60000 (64%)]\tLoss:2.249754\n",
      "train epoch: 1 [39040/60000 (65%)]\tLoss:2.250664\n",
      "train epoch: 1 [39680/60000 (66%)]\tLoss:2.242510\n",
      "train epoch: 1 [40320/60000 (67%)]\tLoss:2.237699\n",
      "train epoch: 1 [40960/60000 (68%)]\tLoss:2.249613\n",
      "train epoch: 1 [41600/60000 (69%)]\tLoss:2.228343\n",
      "train epoch: 1 [42240/60000 (70%)]\tLoss:2.246436\n",
      "train epoch: 1 [42880/60000 (71%)]\tLoss:2.237565\n",
      "train epoch: 1 [43520/60000 (72%)]\tLoss:2.227779\n",
      "train epoch: 1 [44160/60000 (74%)]\tLoss:2.222781\n",
      "train epoch: 1 [44800/60000 (75%)]\tLoss:2.215840\n",
      "train epoch: 1 [45440/60000 (76%)]\tLoss:2.184025\n",
      "train epoch: 1 [46080/60000 (77%)]\tLoss:2.168756\n",
      "train epoch: 1 [46720/60000 (78%)]\tLoss:2.186677\n",
      "train epoch: 1 [47360/60000 (79%)]\tLoss:2.169924\n",
      "train epoch: 1 [48000/60000 (80%)]\tLoss:2.161320\n",
      "train epoch: 1 [48640/60000 (81%)]\tLoss:2.143783\n",
      "train epoch: 1 [49280/60000 (82%)]\tLoss:2.117572\n",
      "train epoch: 1 [49920/60000 (83%)]\tLoss:2.133503\n",
      "train epoch: 1 [50560/60000 (84%)]\tLoss:2.085517\n",
      "train epoch: 1 [51200/60000 (85%)]\tLoss:2.093660\n",
      "train epoch: 1 [51840/60000 (86%)]\tLoss:2.037052\n",
      "train epoch: 1 [52480/60000 (87%)]\tLoss:2.054910\n",
      "train epoch: 1 [53120/60000 (88%)]\tLoss:1.974297\n",
      "train epoch: 1 [53760/60000 (90%)]\tLoss:1.988681\n",
      "train epoch: 1 [54400/60000 (91%)]\tLoss:1.900750\n",
      "train epoch: 1 [55040/60000 (92%)]\tLoss:1.865816\n",
      "train epoch: 1 [55680/60000 (93%)]\tLoss:1.881127\n",
      "train epoch: 1 [56320/60000 (94%)]\tLoss:1.844813\n",
      "train epoch: 1 [56960/60000 (95%)]\tLoss:1.712981\n",
      "train epoch: 1 [57600/60000 (96%)]\tLoss:1.631694\n",
      "train epoch: 1 [58240/60000 (97%)]\tLoss:1.670254\n",
      "train epoch: 1 [58880/60000 (98%)]\tLoss:1.556191\n",
      "train epoch: 1 [59520/60000 (99%)]\tLoss:1.500727\n",
      "\n",
      "test set: Average loss: 0.0236, accuracy: 6267/10000 (63%)\n",
      "\n",
      "train epoch: 2 [0/60000 (0%)]\tLoss:1.551151\n",
      "train epoch: 2 [640/60000 (1%)]\tLoss:1.496345\n",
      "train epoch: 2 [1280/60000 (2%)]\tLoss:1.289078\n",
      "train epoch: 2 [1920/60000 (3%)]\tLoss:1.351570\n",
      "train epoch: 2 [2560/60000 (4%)]\tLoss:1.302069\n",
      "train epoch: 2 [3200/60000 (5%)]\tLoss:1.169643\n",
      "train epoch: 2 [3840/60000 (6%)]\tLoss:1.186078\n",
      "train epoch: 2 [4480/60000 (7%)]\tLoss:1.283918\n",
      "train epoch: 2 [5120/60000 (9%)]\tLoss:1.239980\n",
      "train epoch: 2 [5760/60000 (10%)]\tLoss:1.049553\n",
      "train epoch: 2 [6400/60000 (11%)]\tLoss:1.159187\n",
      "train epoch: 2 [7040/60000 (12%)]\tLoss:1.186104\n",
      "train epoch: 2 [7680/60000 (13%)]\tLoss:0.947300\n",
      "train epoch: 2 [8320/60000 (14%)]\tLoss:0.957143\n",
      "train epoch: 2 [8960/60000 (15%)]\tLoss:0.900609\n",
      "train epoch: 2 [9600/60000 (16%)]\tLoss:0.889597\n",
      "train epoch: 2 [10240/60000 (17%)]\tLoss:0.807458\n",
      "train epoch: 2 [10880/60000 (18%)]\tLoss:0.869185\n",
      "train epoch: 2 [11520/60000 (19%)]\tLoss:0.734726\n",
      "train epoch: 2 [12160/60000 (20%)]\tLoss:0.582926\n",
      "train epoch: 2 [12800/60000 (21%)]\tLoss:0.740900\n",
      "train epoch: 2 [13440/60000 (22%)]\tLoss:1.076232\n",
      "train epoch: 2 [14080/60000 (23%)]\tLoss:0.549713\n",
      "train epoch: 2 [14720/60000 (25%)]\tLoss:0.734475\n",
      "train epoch: 2 [15360/60000 (26%)]\tLoss:0.829487\n",
      "train epoch: 2 [16000/60000 (27%)]\tLoss:0.733353\n",
      "train epoch: 2 [16640/60000 (28%)]\tLoss:0.633607\n",
      "train epoch: 2 [17280/60000 (29%)]\tLoss:0.518942\n",
      "train epoch: 2 [17920/60000 (30%)]\tLoss:0.685671\n",
      "train epoch: 2 [18560/60000 (31%)]\tLoss:0.841001\n",
      "train epoch: 2 [19200/60000 (32%)]\tLoss:0.668013\n",
      "train epoch: 2 [19840/60000 (33%)]\tLoss:0.528433\n",
      "train epoch: 2 [20480/60000 (34%)]\tLoss:0.812627\n",
      "train epoch: 2 [21120/60000 (35%)]\tLoss:0.754984\n",
      "train epoch: 2 [21760/60000 (36%)]\tLoss:0.696840\n",
      "train epoch: 2 [22400/60000 (37%)]\tLoss:0.624855\n",
      "train epoch: 2 [23040/60000 (38%)]\tLoss:0.827162\n",
      "train epoch: 2 [23680/60000 (39%)]\tLoss:0.706240\n",
      "train epoch: 2 [24320/60000 (41%)]\tLoss:0.455453\n",
      "train epoch: 2 [24960/60000 (42%)]\tLoss:0.585100\n",
      "train epoch: 2 [25600/60000 (43%)]\tLoss:0.566720\n",
      "train epoch: 2 [26240/60000 (44%)]\tLoss:0.684220\n",
      "train epoch: 2 [26880/60000 (45%)]\tLoss:0.801132\n",
      "train epoch: 2 [27520/60000 (46%)]\tLoss:0.720510\n",
      "train epoch: 2 [28160/60000 (47%)]\tLoss:0.594617\n",
      "train epoch: 2 [28800/60000 (48%)]\tLoss:0.495990\n",
      "train epoch: 2 [29440/60000 (49%)]\tLoss:0.644039\n",
      "train epoch: 2 [30080/60000 (50%)]\tLoss:0.530576\n",
      "train epoch: 2 [30720/60000 (51%)]\tLoss:0.515229\n",
      "train epoch: 2 [31360/60000 (52%)]\tLoss:0.458059\n",
      "train epoch: 2 [32000/60000 (53%)]\tLoss:0.488877\n",
      "train epoch: 2 [32640/60000 (54%)]\tLoss:0.402907\n",
      "train epoch: 2 [33280/60000 (55%)]\tLoss:0.339796\n",
      "train epoch: 2 [33920/60000 (57%)]\tLoss:0.530252\n",
      "train epoch: 2 [34560/60000 (58%)]\tLoss:0.604605\n",
      "train epoch: 2 [35200/60000 (59%)]\tLoss:0.543144\n",
      "train epoch: 2 [35840/60000 (60%)]\tLoss:0.497259\n",
      "train epoch: 2 [36480/60000 (61%)]\tLoss:0.504300\n",
      "train epoch: 2 [37120/60000 (62%)]\tLoss:0.480988\n",
      "train epoch: 2 [37760/60000 (63%)]\tLoss:0.504588\n",
      "train epoch: 2 [38400/60000 (64%)]\tLoss:0.536784\n",
      "train epoch: 2 [39040/60000 (65%)]\tLoss:0.403370\n",
      "train epoch: 2 [39680/60000 (66%)]\tLoss:0.422690\n",
      "train epoch: 2 [40320/60000 (67%)]\tLoss:0.514208\n",
      "train epoch: 2 [40960/60000 (68%)]\tLoss:0.488130\n",
      "train epoch: 2 [41600/60000 (69%)]\tLoss:0.290534\n",
      "train epoch: 2 [42240/60000 (70%)]\tLoss:0.636708\n",
      "train epoch: 2 [42880/60000 (71%)]\tLoss:0.470888\n",
      "train epoch: 2 [43520/60000 (72%)]\tLoss:0.420966\n",
      "train epoch: 2 [44160/60000 (74%)]\tLoss:0.375990\n",
      "train epoch: 2 [44800/60000 (75%)]\tLoss:0.326917\n",
      "train epoch: 2 [45440/60000 (76%)]\tLoss:0.448025\n",
      "train epoch: 2 [46080/60000 (77%)]\tLoss:0.589985\n",
      "train epoch: 2 [46720/60000 (78%)]\tLoss:0.697699\n",
      "train epoch: 2 [47360/60000 (79%)]\tLoss:0.315057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 2 [48000/60000 (80%)]\tLoss:0.354919\n",
      "train epoch: 2 [48640/60000 (81%)]\tLoss:0.403257\n",
      "train epoch: 2 [49280/60000 (82%)]\tLoss:0.630081\n",
      "train epoch: 2 [49920/60000 (83%)]\tLoss:0.408757\n",
      "train epoch: 2 [50560/60000 (84%)]\tLoss:0.511135\n",
      "train epoch: 2 [51200/60000 (85%)]\tLoss:0.356469\n",
      "train epoch: 2 [51840/60000 (86%)]\tLoss:0.298444\n",
      "train epoch: 2 [52480/60000 (87%)]\tLoss:0.279603\n",
      "train epoch: 2 [53120/60000 (88%)]\tLoss:0.348519\n",
      "train epoch: 2 [53760/60000 (90%)]\tLoss:0.412604\n",
      "train epoch: 2 [54400/60000 (91%)]\tLoss:0.162680\n",
      "train epoch: 2 [55040/60000 (92%)]\tLoss:0.429440\n",
      "train epoch: 2 [55680/60000 (93%)]\tLoss:0.578328\n",
      "train epoch: 2 [56320/60000 (94%)]\tLoss:0.528624\n",
      "train epoch: 2 [56960/60000 (95%)]\tLoss:0.492950\n",
      "train epoch: 2 [57600/60000 (96%)]\tLoss:0.415243\n",
      "train epoch: 2 [58240/60000 (97%)]\tLoss:0.361507\n",
      "train epoch: 2 [58880/60000 (98%)]\tLoss:0.459437\n",
      "train epoch: 2 [59520/60000 (99%)]\tLoss:0.490737\n",
      "\n",
      "test set: Average loss: 0.0062, accuracy: 8852/10000 (89%)\n",
      "\n",
      "train epoch: 3 [0/60000 (0%)]\tLoss:0.406339\n",
      "train epoch: 3 [640/60000 (1%)]\tLoss:0.307461\n",
      "train epoch: 3 [1280/60000 (2%)]\tLoss:0.372321\n",
      "train epoch: 3 [1920/60000 (3%)]\tLoss:0.342756\n",
      "train epoch: 3 [2560/60000 (4%)]\tLoss:0.579038\n",
      "train epoch: 3 [3200/60000 (5%)]\tLoss:0.314538\n",
      "train epoch: 3 [3840/60000 (6%)]\tLoss:0.369910\n",
      "train epoch: 3 [4480/60000 (7%)]\tLoss:0.429548\n",
      "train epoch: 3 [5120/60000 (9%)]\tLoss:0.622609\n",
      "train epoch: 3 [5760/60000 (10%)]\tLoss:0.445294\n",
      "train epoch: 3 [6400/60000 (11%)]\tLoss:0.283967\n",
      "train epoch: 3 [7040/60000 (12%)]\tLoss:0.608130\n",
      "train epoch: 3 [7680/60000 (13%)]\tLoss:0.472036\n",
      "train epoch: 3 [8320/60000 (14%)]\tLoss:0.574493\n",
      "train epoch: 3 [8960/60000 (15%)]\tLoss:0.594844\n",
      "train epoch: 3 [9600/60000 (16%)]\tLoss:0.364595\n",
      "train epoch: 3 [10240/60000 (17%)]\tLoss:0.282939\n",
      "train epoch: 3 [10880/60000 (18%)]\tLoss:0.424900\n",
      "train epoch: 3 [11520/60000 (19%)]\tLoss:0.460195\n",
      "train epoch: 3 [12160/60000 (20%)]\tLoss:0.370461\n",
      "train epoch: 3 [12800/60000 (21%)]\tLoss:0.422827\n",
      "train epoch: 3 [13440/60000 (22%)]\tLoss:0.235619\n",
      "train epoch: 3 [14080/60000 (23%)]\tLoss:0.285935\n",
      "train epoch: 3 [14720/60000 (25%)]\tLoss:0.470444\n",
      "train epoch: 3 [15360/60000 (26%)]\tLoss:0.288616\n",
      "train epoch: 3 [16000/60000 (27%)]\tLoss:0.178044\n",
      "train epoch: 3 [16640/60000 (28%)]\tLoss:0.668751\n",
      "train epoch: 3 [17280/60000 (29%)]\tLoss:0.427467\n",
      "train epoch: 3 [17920/60000 (30%)]\tLoss:0.200339\n",
      "train epoch: 3 [18560/60000 (31%)]\tLoss:0.320412\n",
      "train epoch: 3 [19200/60000 (32%)]\tLoss:0.221312\n",
      "train epoch: 3 [19840/60000 (33%)]\tLoss:0.354798\n",
      "train epoch: 3 [20480/60000 (34%)]\tLoss:0.359406\n",
      "train epoch: 3 [21120/60000 (35%)]\tLoss:0.403505\n",
      "train epoch: 3 [21760/60000 (36%)]\tLoss:0.307760\n",
      "train epoch: 3 [22400/60000 (37%)]\tLoss:0.388827\n",
      "train epoch: 3 [23040/60000 (38%)]\tLoss:0.476414\n",
      "train epoch: 3 [23680/60000 (39%)]\tLoss:0.385933\n",
      "train epoch: 3 [24320/60000 (41%)]\tLoss:0.302424\n",
      "train epoch: 3 [24960/60000 (42%)]\tLoss:0.331227\n",
      "train epoch: 3 [25600/60000 (43%)]\tLoss:0.338923\n",
      "train epoch: 3 [26240/60000 (44%)]\tLoss:0.274623\n",
      "train epoch: 3 [26880/60000 (45%)]\tLoss:0.196344\n",
      "train epoch: 3 [27520/60000 (46%)]\tLoss:0.403287\n",
      "train epoch: 3 [28160/60000 (47%)]\tLoss:0.205029\n",
      "train epoch: 3 [28800/60000 (48%)]\tLoss:0.256986\n",
      "train epoch: 3 [29440/60000 (49%)]\tLoss:0.317438\n",
      "train epoch: 3 [30080/60000 (50%)]\tLoss:0.453262\n",
      "train epoch: 3 [30720/60000 (51%)]\tLoss:0.439984\n",
      "train epoch: 3 [31360/60000 (52%)]\tLoss:0.299589\n",
      "train epoch: 3 [32000/60000 (53%)]\tLoss:0.199063\n",
      "train epoch: 3 [32640/60000 (54%)]\tLoss:0.261458\n",
      "train epoch: 3 [33280/60000 (55%)]\tLoss:0.390446\n",
      "train epoch: 3 [33920/60000 (57%)]\tLoss:0.324209\n",
      "train epoch: 3 [34560/60000 (58%)]\tLoss:0.314662\n",
      "train epoch: 3 [35200/60000 (59%)]\tLoss:0.214973\n",
      "train epoch: 3 [35840/60000 (60%)]\tLoss:0.716370\n",
      "train epoch: 3 [36480/60000 (61%)]\tLoss:0.291476\n",
      "train epoch: 3 [37120/60000 (62%)]\tLoss:0.209645\n",
      "train epoch: 3 [37760/60000 (63%)]\tLoss:0.254959\n",
      "train epoch: 3 [38400/60000 (64%)]\tLoss:0.169559\n",
      "train epoch: 3 [39040/60000 (65%)]\tLoss:0.270273\n",
      "train epoch: 3 [39680/60000 (66%)]\tLoss:0.519828\n",
      "train epoch: 3 [40320/60000 (67%)]\tLoss:0.304504\n",
      "train epoch: 3 [40960/60000 (68%)]\tLoss:0.449105\n",
      "train epoch: 3 [41600/60000 (69%)]\tLoss:0.270115\n",
      "train epoch: 3 [42240/60000 (70%)]\tLoss:0.357085\n",
      "train epoch: 3 [42880/60000 (71%)]\tLoss:0.356098\n",
      "train epoch: 3 [43520/60000 (72%)]\tLoss:0.228024\n",
      "train epoch: 3 [44160/60000 (74%)]\tLoss:0.304617\n",
      "train epoch: 3 [44800/60000 (75%)]\tLoss:0.370626\n",
      "train epoch: 3 [45440/60000 (76%)]\tLoss:0.458030\n",
      "train epoch: 3 [46080/60000 (77%)]\tLoss:0.155546\n",
      "train epoch: 3 [46720/60000 (78%)]\tLoss:0.404145\n",
      "train epoch: 3 [47360/60000 (79%)]\tLoss:0.274225\n",
      "train epoch: 3 [48000/60000 (80%)]\tLoss:0.313853\n",
      "train epoch: 3 [48640/60000 (81%)]\tLoss:0.251310\n",
      "train epoch: 3 [49280/60000 (82%)]\tLoss:0.228912\n",
      "train epoch: 3 [49920/60000 (83%)]\tLoss:0.215841\n",
      "train epoch: 3 [50560/60000 (84%)]\tLoss:0.189417\n",
      "train epoch: 3 [51200/60000 (85%)]\tLoss:0.306121\n",
      "train epoch: 3 [51840/60000 (86%)]\tLoss:0.183116\n",
      "train epoch: 3 [52480/60000 (87%)]\tLoss:0.304672\n",
      "train epoch: 3 [53120/60000 (88%)]\tLoss:0.186561\n",
      "train epoch: 3 [53760/60000 (90%)]\tLoss:0.435191\n",
      "train epoch: 3 [54400/60000 (91%)]\tLoss:0.298713\n",
      "train epoch: 3 [55040/60000 (92%)]\tLoss:0.179314\n",
      "train epoch: 3 [55680/60000 (93%)]\tLoss:0.351258\n",
      "train epoch: 3 [56320/60000 (94%)]\tLoss:0.405753\n",
      "train epoch: 3 [56960/60000 (95%)]\tLoss:0.408967\n",
      "train epoch: 3 [57600/60000 (96%)]\tLoss:0.276881\n",
      "train epoch: 3 [58240/60000 (97%)]\tLoss:0.268335\n",
      "train epoch: 3 [58880/60000 (98%)]\tLoss:0.519569\n",
      "train epoch: 3 [59520/60000 (99%)]\tLoss:0.310959\n",
      "\n",
      "test set: Average loss: 0.0046, accuracy: 9118/10000 (91%)\n",
      "\n",
      "train epoch: 4 [0/60000 (0%)]\tLoss:0.412958\n",
      "train epoch: 4 [640/60000 (1%)]\tLoss:0.238966\n",
      "train epoch: 4 [1280/60000 (2%)]\tLoss:0.244865\n",
      "train epoch: 4 [1920/60000 (3%)]\tLoss:0.205620\n",
      "train epoch: 4 [2560/60000 (4%)]\tLoss:0.197174\n",
      "train epoch: 4 [3200/60000 (5%)]\tLoss:0.287529\n",
      "train epoch: 4 [3840/60000 (6%)]\tLoss:0.153334\n",
      "train epoch: 4 [4480/60000 (7%)]\tLoss:0.574764\n",
      "train epoch: 4 [5120/60000 (9%)]\tLoss:0.232441\n",
      "train epoch: 4 [5760/60000 (10%)]\tLoss:0.304173\n",
      "train epoch: 4 [6400/60000 (11%)]\tLoss:0.227455\n",
      "train epoch: 4 [7040/60000 (12%)]\tLoss:0.214981\n",
      "train epoch: 4 [7680/60000 (13%)]\tLoss:0.288851\n",
      "train epoch: 4 [8320/60000 (14%)]\tLoss:0.293344\n",
      "train epoch: 4 [8960/60000 (15%)]\tLoss:0.271394\n",
      "train epoch: 4 [9600/60000 (16%)]\tLoss:0.345905\n",
      "train epoch: 4 [10240/60000 (17%)]\tLoss:0.489460\n",
      "train epoch: 4 [10880/60000 (18%)]\tLoss:0.294940\n",
      "train epoch: 4 [11520/60000 (19%)]\tLoss:0.370223\n",
      "train epoch: 4 [12160/60000 (20%)]\tLoss:0.335406\n",
      "train epoch: 4 [12800/60000 (21%)]\tLoss:0.335279\n",
      "train epoch: 4 [13440/60000 (22%)]\tLoss:0.473725\n",
      "train epoch: 4 [14080/60000 (23%)]\tLoss:0.070265\n",
      "train epoch: 4 [14720/60000 (25%)]\tLoss:0.230866\n",
      "train epoch: 4 [15360/60000 (26%)]\tLoss:0.208575\n",
      "train epoch: 4 [16000/60000 (27%)]\tLoss:0.143537\n",
      "train epoch: 4 [16640/60000 (28%)]\tLoss:0.200191\n",
      "train epoch: 4 [17280/60000 (29%)]\tLoss:0.345716\n",
      "train epoch: 4 [17920/60000 (30%)]\tLoss:0.229193\n",
      "train epoch: 4 [18560/60000 (31%)]\tLoss:0.156771\n",
      "train epoch: 4 [19200/60000 (32%)]\tLoss:0.316254\n",
      "train epoch: 4 [19840/60000 (33%)]\tLoss:0.498747\n",
      "train epoch: 4 [20480/60000 (34%)]\tLoss:0.258685\n",
      "train epoch: 4 [21120/60000 (35%)]\tLoss:0.324945\n",
      "train epoch: 4 [21760/60000 (36%)]\tLoss:0.341624\n",
      "train epoch: 4 [22400/60000 (37%)]\tLoss:0.372507\n",
      "train epoch: 4 [23040/60000 (38%)]\tLoss:0.438374\n",
      "train epoch: 4 [23680/60000 (39%)]\tLoss:0.105535\n",
      "train epoch: 4 [24320/60000 (41%)]\tLoss:0.236133\n",
      "train epoch: 4 [24960/60000 (42%)]\tLoss:0.383393\n",
      "train epoch: 4 [25600/60000 (43%)]\tLoss:0.180678\n",
      "train epoch: 4 [26240/60000 (44%)]\tLoss:0.159105\n",
      "train epoch: 4 [26880/60000 (45%)]\tLoss:0.285910\n",
      "train epoch: 4 [27520/60000 (46%)]\tLoss:0.327313\n",
      "train epoch: 4 [28160/60000 (47%)]\tLoss:0.262840\n",
      "train epoch: 4 [28800/60000 (48%)]\tLoss:0.175502\n",
      "train epoch: 4 [29440/60000 (49%)]\tLoss:0.147926\n",
      "train epoch: 4 [30080/60000 (50%)]\tLoss:0.326430\n",
      "train epoch: 4 [30720/60000 (51%)]\tLoss:0.183764\n",
      "train epoch: 4 [31360/60000 (52%)]\tLoss:0.211045\n",
      "train epoch: 4 [32000/60000 (53%)]\tLoss:0.486910\n",
      "train epoch: 4 [32640/60000 (54%)]\tLoss:0.245589\n",
      "train epoch: 4 [33280/60000 (55%)]\tLoss:0.278814\n",
      "train epoch: 4 [33920/60000 (57%)]\tLoss:0.315432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 4 [34560/60000 (58%)]\tLoss:0.343413\n",
      "train epoch: 4 [35200/60000 (59%)]\tLoss:0.534073\n",
      "train epoch: 4 [35840/60000 (60%)]\tLoss:0.263464\n",
      "train epoch: 4 [36480/60000 (61%)]\tLoss:0.214221\n",
      "train epoch: 4 [37120/60000 (62%)]\tLoss:0.300203\n",
      "train epoch: 4 [37760/60000 (63%)]\tLoss:0.480112\n",
      "train epoch: 4 [38400/60000 (64%)]\tLoss:0.266444\n",
      "train epoch: 4 [39040/60000 (65%)]\tLoss:0.251678\n",
      "train epoch: 4 [39680/60000 (66%)]\tLoss:0.215231\n",
      "train epoch: 4 [40320/60000 (67%)]\tLoss:0.256135\n",
      "train epoch: 4 [40960/60000 (68%)]\tLoss:0.140839\n",
      "train epoch: 4 [41600/60000 (69%)]\tLoss:0.305250\n",
      "train epoch: 4 [42240/60000 (70%)]\tLoss:0.242423\n",
      "train epoch: 4 [42880/60000 (71%)]\tLoss:0.260606\n",
      "train epoch: 4 [43520/60000 (72%)]\tLoss:0.164500\n",
      "train epoch: 4 [44160/60000 (74%)]\tLoss:0.257563\n",
      "train epoch: 4 [44800/60000 (75%)]\tLoss:0.267580\n",
      "train epoch: 4 [45440/60000 (76%)]\tLoss:0.321925\n",
      "train epoch: 4 [46080/60000 (77%)]\tLoss:0.304677\n",
      "train epoch: 4 [46720/60000 (78%)]\tLoss:0.306326\n",
      "train epoch: 4 [47360/60000 (79%)]\tLoss:0.229489\n",
      "train epoch: 4 [48000/60000 (80%)]\tLoss:0.220242\n",
      "train epoch: 4 [48640/60000 (81%)]\tLoss:0.247299\n",
      "train epoch: 4 [49280/60000 (82%)]\tLoss:0.269503\n",
      "train epoch: 4 [49920/60000 (83%)]\tLoss:0.296281\n",
      "train epoch: 4 [50560/60000 (84%)]\tLoss:0.244135\n",
      "train epoch: 4 [51200/60000 (85%)]\tLoss:0.181187\n",
      "train epoch: 4 [51840/60000 (86%)]\tLoss:0.335801\n",
      "train epoch: 4 [52480/60000 (87%)]\tLoss:0.199336\n",
      "train epoch: 4 [53120/60000 (88%)]\tLoss:0.222687\n",
      "train epoch: 4 [53760/60000 (90%)]\tLoss:0.159508\n",
      "train epoch: 4 [54400/60000 (91%)]\tLoss:0.152767\n",
      "train epoch: 4 [55040/60000 (92%)]\tLoss:0.296465\n",
      "train epoch: 4 [55680/60000 (93%)]\tLoss:0.098405\n",
      "train epoch: 4 [56320/60000 (94%)]\tLoss:0.270704\n",
      "train epoch: 4 [56960/60000 (95%)]\tLoss:0.256745\n",
      "train epoch: 4 [57600/60000 (96%)]\tLoss:0.113108\n",
      "train epoch: 4 [58240/60000 (97%)]\tLoss:0.259256\n",
      "train epoch: 4 [58880/60000 (98%)]\tLoss:0.522709\n",
      "train epoch: 4 [59520/60000 (99%)]\tLoss:0.184719\n",
      "\n",
      "test set: Average loss: 0.0035, accuracy: 9340/10000 (93%)\n",
      "\n",
      "train epoch: 5 [0/60000 (0%)]\tLoss:0.357605\n",
      "train epoch: 5 [640/60000 (1%)]\tLoss:0.249501\n",
      "train epoch: 5 [1280/60000 (2%)]\tLoss:0.308715\n",
      "train epoch: 5 [1920/60000 (3%)]\tLoss:0.381905\n",
      "train epoch: 5 [2560/60000 (4%)]\tLoss:0.589599\n",
      "train epoch: 5 [3200/60000 (5%)]\tLoss:0.178409\n",
      "train epoch: 5 [3840/60000 (6%)]\tLoss:0.166532\n",
      "train epoch: 5 [4480/60000 (7%)]\tLoss:0.198546\n",
      "train epoch: 5 [5120/60000 (9%)]\tLoss:0.080031\n",
      "train epoch: 5 [5760/60000 (10%)]\tLoss:0.455359\n",
      "train epoch: 5 [6400/60000 (11%)]\tLoss:0.093339\n",
      "train epoch: 5 [7040/60000 (12%)]\tLoss:0.219935\n",
      "train epoch: 5 [7680/60000 (13%)]\tLoss:0.137378\n",
      "train epoch: 5 [8320/60000 (14%)]\tLoss:0.153416\n",
      "train epoch: 5 [8960/60000 (15%)]\tLoss:0.176492\n",
      "train epoch: 5 [9600/60000 (16%)]\tLoss:0.154365\n",
      "train epoch: 5 [10240/60000 (17%)]\tLoss:0.100515\n",
      "train epoch: 5 [10880/60000 (18%)]\tLoss:0.161150\n",
      "train epoch: 5 [11520/60000 (19%)]\tLoss:0.141182\n",
      "train epoch: 5 [12160/60000 (20%)]\tLoss:0.165361\n",
      "train epoch: 5 [12800/60000 (21%)]\tLoss:0.335585\n",
      "train epoch: 5 [13440/60000 (22%)]\tLoss:0.068527\n",
      "train epoch: 5 [14080/60000 (23%)]\tLoss:0.079918\n",
      "train epoch: 5 [14720/60000 (25%)]\tLoss:0.271836\n",
      "train epoch: 5 [15360/60000 (26%)]\tLoss:0.336551\n",
      "train epoch: 5 [16000/60000 (27%)]\tLoss:0.112788\n",
      "train epoch: 5 [16640/60000 (28%)]\tLoss:0.165624\n",
      "train epoch: 5 [17280/60000 (29%)]\tLoss:0.207966\n",
      "train epoch: 5 [17920/60000 (30%)]\tLoss:0.097411\n",
      "train epoch: 5 [18560/60000 (31%)]\tLoss:0.251592\n",
      "train epoch: 5 [19200/60000 (32%)]\tLoss:0.311489\n",
      "train epoch: 5 [19840/60000 (33%)]\tLoss:0.230978\n",
      "train epoch: 5 [20480/60000 (34%)]\tLoss:0.143462\n",
      "train epoch: 5 [21120/60000 (35%)]\tLoss:0.312078\n",
      "train epoch: 5 [21760/60000 (36%)]\tLoss:0.139039\n",
      "train epoch: 5 [22400/60000 (37%)]\tLoss:0.174791\n",
      "train epoch: 5 [23040/60000 (38%)]\tLoss:0.054202\n",
      "train epoch: 5 [23680/60000 (39%)]\tLoss:0.136499\n",
      "train epoch: 5 [24320/60000 (41%)]\tLoss:0.286930\n",
      "train epoch: 5 [24960/60000 (42%)]\tLoss:0.111018\n",
      "train epoch: 5 [25600/60000 (43%)]\tLoss:0.374803\n",
      "train epoch: 5 [26240/60000 (44%)]\tLoss:0.259692\n",
      "train epoch: 5 [26880/60000 (45%)]\tLoss:0.351168\n",
      "train epoch: 5 [27520/60000 (46%)]\tLoss:0.148207\n",
      "train epoch: 5 [28160/60000 (47%)]\tLoss:0.428314\n",
      "train epoch: 5 [28800/60000 (48%)]\tLoss:0.167278\n",
      "train epoch: 5 [29440/60000 (49%)]\tLoss:0.310777\n",
      "train epoch: 5 [30080/60000 (50%)]\tLoss:0.156270\n",
      "train epoch: 5 [30720/60000 (51%)]\tLoss:0.323140\n",
      "train epoch: 5 [31360/60000 (52%)]\tLoss:0.180718\n",
      "train epoch: 5 [32000/60000 (53%)]\tLoss:0.195357\n",
      "train epoch: 5 [32640/60000 (54%)]\tLoss:0.262661\n",
      "train epoch: 5 [33280/60000 (55%)]\tLoss:0.157521\n",
      "train epoch: 5 [33920/60000 (57%)]\tLoss:0.114021\n",
      "train epoch: 5 [34560/60000 (58%)]\tLoss:0.122442\n",
      "train epoch: 5 [35200/60000 (59%)]\tLoss:0.296977\n",
      "train epoch: 5 [35840/60000 (60%)]\tLoss:0.170775\n",
      "train epoch: 5 [36480/60000 (61%)]\tLoss:0.363379\n",
      "train epoch: 5 [37120/60000 (62%)]\tLoss:0.187531\n",
      "train epoch: 5 [37760/60000 (63%)]\tLoss:0.167304\n",
      "train epoch: 5 [38400/60000 (64%)]\tLoss:0.082083\n",
      "train epoch: 5 [39040/60000 (65%)]\tLoss:0.121834\n",
      "train epoch: 5 [39680/60000 (66%)]\tLoss:0.066269\n",
      "train epoch: 5 [40320/60000 (67%)]\tLoss:0.212531\n",
      "train epoch: 5 [40960/60000 (68%)]\tLoss:0.131574\n",
      "train epoch: 5 [41600/60000 (69%)]\tLoss:0.051622\n",
      "train epoch: 5 [42240/60000 (70%)]\tLoss:0.120014\n",
      "train epoch: 5 [42880/60000 (71%)]\tLoss:0.148171\n",
      "train epoch: 5 [43520/60000 (72%)]\tLoss:0.170327\n",
      "train epoch: 5 [44160/60000 (74%)]\tLoss:0.202417\n",
      "train epoch: 5 [44800/60000 (75%)]\tLoss:0.232516\n",
      "train epoch: 5 [45440/60000 (76%)]\tLoss:0.270384\n",
      "train epoch: 5 [46080/60000 (77%)]\tLoss:0.215524\n",
      "train epoch: 5 [46720/60000 (78%)]\tLoss:0.118752\n",
      "train epoch: 5 [47360/60000 (79%)]\tLoss:0.164376\n",
      "train epoch: 5 [48000/60000 (80%)]\tLoss:0.129531\n",
      "train epoch: 5 [48640/60000 (81%)]\tLoss:0.298406\n",
      "train epoch: 5 [49280/60000 (82%)]\tLoss:0.143756\n",
      "train epoch: 5 [49920/60000 (83%)]\tLoss:0.192898\n",
      "train epoch: 5 [50560/60000 (84%)]\tLoss:0.183098\n",
      "train epoch: 5 [51200/60000 (85%)]\tLoss:0.294748\n",
      "train epoch: 5 [51840/60000 (86%)]\tLoss:0.224524\n",
      "train epoch: 5 [52480/60000 (87%)]\tLoss:0.150863\n",
      "train epoch: 5 [53120/60000 (88%)]\tLoss:0.114542\n",
      "train epoch: 5 [53760/60000 (90%)]\tLoss:0.190779\n",
      "train epoch: 5 [54400/60000 (91%)]\tLoss:0.271722\n",
      "train epoch: 5 [55040/60000 (92%)]\tLoss:0.098098\n",
      "train epoch: 5 [55680/60000 (93%)]\tLoss:0.195049\n",
      "train epoch: 5 [56320/60000 (94%)]\tLoss:0.143267\n",
      "train epoch: 5 [56960/60000 (95%)]\tLoss:0.157178\n",
      "train epoch: 5 [57600/60000 (96%)]\tLoss:0.112673\n",
      "train epoch: 5 [58240/60000 (97%)]\tLoss:0.290253\n",
      "train epoch: 5 [58880/60000 (98%)]\tLoss:0.252476\n",
      "train epoch: 5 [59520/60000 (99%)]\tLoss:0.109097\n",
      "\n",
      "test set: Average loss: 0.0028, accuracy: 9461/10000 (95%)\n",
      "\n",
      "train epoch: 6 [0/60000 (0%)]\tLoss:0.217784\n",
      "train epoch: 6 [640/60000 (1%)]\tLoss:0.197135\n",
      "train epoch: 6 [1280/60000 (2%)]\tLoss:0.172343\n",
      "train epoch: 6 [1920/60000 (3%)]\tLoss:0.218458\n",
      "train epoch: 6 [2560/60000 (4%)]\tLoss:0.085956\n",
      "train epoch: 6 [3200/60000 (5%)]\tLoss:0.037929\n",
      "train epoch: 6 [3840/60000 (6%)]\tLoss:0.311961\n",
      "train epoch: 6 [4480/60000 (7%)]\tLoss:0.119884\n",
      "train epoch: 6 [5120/60000 (9%)]\tLoss:0.241692\n",
      "train epoch: 6 [5760/60000 (10%)]\tLoss:0.284956\n",
      "train epoch: 6 [6400/60000 (11%)]\tLoss:0.257617\n",
      "train epoch: 6 [7040/60000 (12%)]\tLoss:0.214015\n",
      "train epoch: 6 [7680/60000 (13%)]\tLoss:0.069394\n",
      "train epoch: 6 [8320/60000 (14%)]\tLoss:0.091661\n",
      "train epoch: 6 [8960/60000 (15%)]\tLoss:0.241089\n",
      "train epoch: 6 [9600/60000 (16%)]\tLoss:0.137244\n",
      "train epoch: 6 [10240/60000 (17%)]\tLoss:0.243541\n",
      "train epoch: 6 [10880/60000 (18%)]\tLoss:0.129330\n",
      "train epoch: 6 [11520/60000 (19%)]\tLoss:0.109136\n",
      "train epoch: 6 [12160/60000 (20%)]\tLoss:0.042681\n",
      "train epoch: 6 [12800/60000 (21%)]\tLoss:0.149543\n",
      "train epoch: 6 [13440/60000 (22%)]\tLoss:0.187945\n",
      "train epoch: 6 [14080/60000 (23%)]\tLoss:0.272099\n",
      "train epoch: 6 [14720/60000 (25%)]\tLoss:0.225210\n",
      "train epoch: 6 [15360/60000 (26%)]\tLoss:0.105543\n",
      "train epoch: 6 [16000/60000 (27%)]\tLoss:0.089720\n",
      "train epoch: 6 [16640/60000 (28%)]\tLoss:0.131543\n",
      "train epoch: 6 [17280/60000 (29%)]\tLoss:0.166717\n",
      "train epoch: 6 [17920/60000 (30%)]\tLoss:0.162735\n",
      "train epoch: 6 [18560/60000 (31%)]\tLoss:0.109481\n",
      "train epoch: 6 [19200/60000 (32%)]\tLoss:0.176727\n",
      "train epoch: 6 [19840/60000 (33%)]\tLoss:0.181602\n",
      "train epoch: 6 [20480/60000 (34%)]\tLoss:0.399857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 6 [21120/60000 (35%)]\tLoss:0.185003\n",
      "train epoch: 6 [21760/60000 (36%)]\tLoss:0.122266\n",
      "train epoch: 6 [22400/60000 (37%)]\tLoss:0.286210\n",
      "train epoch: 6 [23040/60000 (38%)]\tLoss:0.388133\n",
      "train epoch: 6 [23680/60000 (39%)]\tLoss:0.152254\n",
      "train epoch: 6 [24320/60000 (41%)]\tLoss:0.226305\n",
      "train epoch: 6 [24960/60000 (42%)]\tLoss:0.202891\n",
      "train epoch: 6 [25600/60000 (43%)]\tLoss:0.086874\n",
      "train epoch: 6 [26240/60000 (44%)]\tLoss:0.070430\n",
      "train epoch: 6 [26880/60000 (45%)]\tLoss:0.139437\n",
      "train epoch: 6 [27520/60000 (46%)]\tLoss:0.139086\n",
      "train epoch: 6 [28160/60000 (47%)]\tLoss:0.213348\n",
      "train epoch: 6 [28800/60000 (48%)]\tLoss:0.282848\n",
      "train epoch: 6 [29440/60000 (49%)]\tLoss:0.119197\n",
      "train epoch: 6 [30080/60000 (50%)]\tLoss:0.211702\n",
      "train epoch: 6 [30720/60000 (51%)]\tLoss:0.268020\n",
      "train epoch: 6 [31360/60000 (52%)]\tLoss:0.249045\n",
      "train epoch: 6 [32000/60000 (53%)]\tLoss:0.260635\n",
      "train epoch: 6 [32640/60000 (54%)]\tLoss:0.385800\n",
      "train epoch: 6 [33280/60000 (55%)]\tLoss:0.223099\n",
      "train epoch: 6 [33920/60000 (57%)]\tLoss:0.192028\n",
      "train epoch: 6 [34560/60000 (58%)]\tLoss:0.115650\n",
      "train epoch: 6 [35200/60000 (59%)]\tLoss:0.145477\n",
      "train epoch: 6 [35840/60000 (60%)]\tLoss:0.062084\n",
      "train epoch: 6 [36480/60000 (61%)]\tLoss:0.058421\n",
      "train epoch: 6 [37120/60000 (62%)]\tLoss:0.081073\n",
      "train epoch: 6 [37760/60000 (63%)]\tLoss:0.113770\n",
      "train epoch: 6 [38400/60000 (64%)]\tLoss:0.097999\n",
      "train epoch: 6 [39040/60000 (65%)]\tLoss:0.276902\n",
      "train epoch: 6 [39680/60000 (66%)]\tLoss:0.216467\n",
      "train epoch: 6 [40320/60000 (67%)]\tLoss:0.173857\n",
      "train epoch: 6 [40960/60000 (68%)]\tLoss:0.292056\n",
      "train epoch: 6 [41600/60000 (69%)]\tLoss:0.112510\n",
      "train epoch: 6 [42240/60000 (70%)]\tLoss:0.196044\n",
      "train epoch: 6 [42880/60000 (71%)]\tLoss:0.085505\n",
      "train epoch: 6 [43520/60000 (72%)]\tLoss:0.245370\n",
      "train epoch: 6 [44160/60000 (74%)]\tLoss:0.326232\n",
      "train epoch: 6 [44800/60000 (75%)]\tLoss:0.101290\n",
      "train epoch: 6 [45440/60000 (76%)]\tLoss:0.103973\n",
      "train epoch: 6 [46080/60000 (77%)]\tLoss:0.201281\n",
      "train epoch: 6 [46720/60000 (78%)]\tLoss:0.128657\n",
      "train epoch: 6 [47360/60000 (79%)]\tLoss:0.067507\n",
      "train epoch: 6 [48000/60000 (80%)]\tLoss:0.080591\n",
      "train epoch: 6 [48640/60000 (81%)]\tLoss:0.243649\n",
      "train epoch: 6 [49280/60000 (82%)]\tLoss:0.127262\n",
      "train epoch: 6 [49920/60000 (83%)]\tLoss:0.165621\n",
      "train epoch: 6 [50560/60000 (84%)]\tLoss:0.045196\n",
      "train epoch: 6 [51200/60000 (85%)]\tLoss:0.127356\n",
      "train epoch: 6 [51840/60000 (86%)]\tLoss:0.093810\n",
      "train epoch: 6 [52480/60000 (87%)]\tLoss:0.125511\n",
      "train epoch: 6 [53120/60000 (88%)]\tLoss:0.192148\n",
      "train epoch: 6 [53760/60000 (90%)]\tLoss:0.220239\n",
      "train epoch: 6 [54400/60000 (91%)]\tLoss:0.066907\n",
      "train epoch: 6 [55040/60000 (92%)]\tLoss:0.123278\n",
      "train epoch: 6 [55680/60000 (93%)]\tLoss:0.089346\n",
      "train epoch: 6 [56320/60000 (94%)]\tLoss:0.101928\n",
      "train epoch: 6 [56960/60000 (95%)]\tLoss:0.151682\n",
      "train epoch: 6 [57600/60000 (96%)]\tLoss:0.159783\n",
      "train epoch: 6 [58240/60000 (97%)]\tLoss:0.189550\n",
      "train epoch: 6 [58880/60000 (98%)]\tLoss:0.224593\n",
      "train epoch: 6 [59520/60000 (99%)]\tLoss:0.165472\n",
      "\n",
      "test set: Average loss: 0.0023, accuracy: 9569/10000 (96%)\n",
      "\n",
      "train epoch: 7 [0/60000 (0%)]\tLoss:0.188285\n",
      "train epoch: 7 [640/60000 (1%)]\tLoss:0.133888\n",
      "train epoch: 7 [1280/60000 (2%)]\tLoss:0.110402\n",
      "train epoch: 7 [1920/60000 (3%)]\tLoss:0.113248\n",
      "train epoch: 7 [2560/60000 (4%)]\tLoss:0.121601\n",
      "train epoch: 7 [3200/60000 (5%)]\tLoss:0.140132\n",
      "train epoch: 7 [3840/60000 (6%)]\tLoss:0.139542\n",
      "train epoch: 7 [4480/60000 (7%)]\tLoss:0.184220\n",
      "train epoch: 7 [5120/60000 (9%)]\tLoss:0.094514\n",
      "train epoch: 7 [5760/60000 (10%)]\tLoss:0.094835\n",
      "train epoch: 7 [6400/60000 (11%)]\tLoss:0.173966\n",
      "train epoch: 7 [7040/60000 (12%)]\tLoss:0.074317\n",
      "train epoch: 7 [7680/60000 (13%)]\tLoss:0.223239\n",
      "train epoch: 7 [8320/60000 (14%)]\tLoss:0.158884\n",
      "train epoch: 7 [8960/60000 (15%)]\tLoss:0.145439\n",
      "train epoch: 7 [9600/60000 (16%)]\tLoss:0.092887\n",
      "train epoch: 7 [10240/60000 (17%)]\tLoss:0.227418\n",
      "train epoch: 7 [10880/60000 (18%)]\tLoss:0.249688\n",
      "train epoch: 7 [11520/60000 (19%)]\tLoss:0.042917\n",
      "train epoch: 7 [12160/60000 (20%)]\tLoss:0.140886\n",
      "train epoch: 7 [12800/60000 (21%)]\tLoss:0.198212\n",
      "train epoch: 7 [13440/60000 (22%)]\tLoss:0.171445\n",
      "train epoch: 7 [14080/60000 (23%)]\tLoss:0.057989\n",
      "train epoch: 7 [14720/60000 (25%)]\tLoss:0.124956\n",
      "train epoch: 7 [15360/60000 (26%)]\tLoss:0.107413\n",
      "train epoch: 7 [16000/60000 (27%)]\tLoss:0.076424\n",
      "train epoch: 7 [16640/60000 (28%)]\tLoss:0.027303\n",
      "train epoch: 7 [17280/60000 (29%)]\tLoss:0.172057\n",
      "train epoch: 7 [17920/60000 (30%)]\tLoss:0.136905\n",
      "train epoch: 7 [18560/60000 (31%)]\tLoss:0.121942\n",
      "train epoch: 7 [19200/60000 (32%)]\tLoss:0.065631\n",
      "train epoch: 7 [19840/60000 (33%)]\tLoss:0.235767\n",
      "train epoch: 7 [20480/60000 (34%)]\tLoss:0.086294\n",
      "train epoch: 7 [21120/60000 (35%)]\tLoss:0.114921\n",
      "train epoch: 7 [21760/60000 (36%)]\tLoss:0.186511\n",
      "train epoch: 7 [22400/60000 (37%)]\tLoss:0.091793\n",
      "train epoch: 7 [23040/60000 (38%)]\tLoss:0.173533\n",
      "train epoch: 7 [23680/60000 (39%)]\tLoss:0.193856\n",
      "train epoch: 7 [24320/60000 (41%)]\tLoss:0.052173\n",
      "train epoch: 7 [24960/60000 (42%)]\tLoss:0.241577\n",
      "train epoch: 7 [25600/60000 (43%)]\tLoss:0.241767\n",
      "train epoch: 7 [26240/60000 (44%)]\tLoss:0.091282\n",
      "train epoch: 7 [26880/60000 (45%)]\tLoss:0.253578\n",
      "train epoch: 7 [27520/60000 (46%)]\tLoss:0.139497\n",
      "train epoch: 7 [28160/60000 (47%)]\tLoss:0.141739\n",
      "train epoch: 7 [28800/60000 (48%)]\tLoss:0.081342\n",
      "train epoch: 7 [29440/60000 (49%)]\tLoss:0.035492\n",
      "train epoch: 7 [30080/60000 (50%)]\tLoss:0.157135\n",
      "train epoch: 7 [30720/60000 (51%)]\tLoss:0.101740\n",
      "train epoch: 7 [31360/60000 (52%)]\tLoss:0.106623\n",
      "train epoch: 7 [32000/60000 (53%)]\tLoss:0.413396\n",
      "train epoch: 7 [32640/60000 (54%)]\tLoss:0.075127\n",
      "train epoch: 7 [33280/60000 (55%)]\tLoss:0.237141\n",
      "train epoch: 7 [33920/60000 (57%)]\tLoss:0.077530\n",
      "train epoch: 7 [34560/60000 (58%)]\tLoss:0.307391\n",
      "train epoch: 7 [35200/60000 (59%)]\tLoss:0.098030\n",
      "train epoch: 7 [35840/60000 (60%)]\tLoss:0.153625\n",
      "train epoch: 7 [36480/60000 (61%)]\tLoss:0.041588\n",
      "train epoch: 7 [37120/60000 (62%)]\tLoss:0.031238\n",
      "train epoch: 7 [37760/60000 (63%)]\tLoss:0.103481\n",
      "train epoch: 7 [38400/60000 (64%)]\tLoss:0.041884\n",
      "train epoch: 7 [39040/60000 (65%)]\tLoss:0.130651\n",
      "train epoch: 7 [39680/60000 (66%)]\tLoss:0.094178\n",
      "train epoch: 7 [40320/60000 (67%)]\tLoss:0.065040\n",
      "train epoch: 7 [40960/60000 (68%)]\tLoss:0.138199\n",
      "train epoch: 7 [41600/60000 (69%)]\tLoss:0.109440\n",
      "train epoch: 7 [42240/60000 (70%)]\tLoss:0.076302\n",
      "train epoch: 7 [42880/60000 (71%)]\tLoss:0.130891\n",
      "train epoch: 7 [43520/60000 (72%)]\tLoss:0.141806\n",
      "train epoch: 7 [44160/60000 (74%)]\tLoss:0.097299\n",
      "train epoch: 7 [44800/60000 (75%)]\tLoss:0.129857\n",
      "train epoch: 7 [45440/60000 (76%)]\tLoss:0.200665\n",
      "train epoch: 7 [46080/60000 (77%)]\tLoss:0.117401\n",
      "train epoch: 7 [46720/60000 (78%)]\tLoss:0.057711\n",
      "train epoch: 7 [47360/60000 (79%)]\tLoss:0.171866\n",
      "train epoch: 7 [48000/60000 (80%)]\tLoss:0.076614\n",
      "train epoch: 7 [48640/60000 (81%)]\tLoss:0.077515\n",
      "train epoch: 7 [49280/60000 (82%)]\tLoss:0.221589\n",
      "train epoch: 7 [49920/60000 (83%)]\tLoss:0.072453\n",
      "train epoch: 7 [50560/60000 (84%)]\tLoss:0.129324\n",
      "train epoch: 7 [51200/60000 (85%)]\tLoss:0.108716\n",
      "train epoch: 7 [51840/60000 (86%)]\tLoss:0.165506\n",
      "train epoch: 7 [52480/60000 (87%)]\tLoss:0.271804\n",
      "train epoch: 7 [53120/60000 (88%)]\tLoss:0.152627\n",
      "train epoch: 7 [53760/60000 (90%)]\tLoss:0.057823\n",
      "train epoch: 7 [54400/60000 (91%)]\tLoss:0.093090\n",
      "train epoch: 7 [55040/60000 (92%)]\tLoss:0.037081\n",
      "train epoch: 7 [55680/60000 (93%)]\tLoss:0.030941\n",
      "train epoch: 7 [56320/60000 (94%)]\tLoss:0.147755\n",
      "train epoch: 7 [56960/60000 (95%)]\tLoss:0.069130\n",
      "train epoch: 7 [57600/60000 (96%)]\tLoss:0.076770\n",
      "train epoch: 7 [58240/60000 (97%)]\tLoss:0.129123\n",
      "train epoch: 7 [58880/60000 (98%)]\tLoss:0.071541\n",
      "train epoch: 7 [59520/60000 (99%)]\tLoss:0.049096\n",
      "\n",
      "test set: Average loss: 0.0020, accuracy: 9635/10000 (96%)\n",
      "\n",
      "train epoch: 8 [0/60000 (0%)]\tLoss:0.092662\n",
      "train epoch: 8 [640/60000 (1%)]\tLoss:0.075348\n",
      "train epoch: 8 [1280/60000 (2%)]\tLoss:0.110502\n",
      "train epoch: 8 [1920/60000 (3%)]\tLoss:0.182408\n",
      "train epoch: 8 [2560/60000 (4%)]\tLoss:0.051161\n",
      "train epoch: 8 [3200/60000 (5%)]\tLoss:0.104930\n",
      "train epoch: 8 [3840/60000 (6%)]\tLoss:0.112620\n",
      "train epoch: 8 [4480/60000 (7%)]\tLoss:0.016875\n",
      "train epoch: 8 [5120/60000 (9%)]\tLoss:0.065950\n",
      "train epoch: 8 [5760/60000 (10%)]\tLoss:0.096639\n",
      "train epoch: 8 [6400/60000 (11%)]\tLoss:0.132496\n",
      "train epoch: 8 [7040/60000 (12%)]\tLoss:0.151706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 8 [7680/60000 (13%)]\tLoss:0.099864\n",
      "train epoch: 8 [8320/60000 (14%)]\tLoss:0.111855\n",
      "train epoch: 8 [8960/60000 (15%)]\tLoss:0.097492\n",
      "train epoch: 8 [9600/60000 (16%)]\tLoss:0.200248\n",
      "train epoch: 8 [10240/60000 (17%)]\tLoss:0.176311\n",
      "train epoch: 8 [10880/60000 (18%)]\tLoss:0.058712\n",
      "train epoch: 8 [11520/60000 (19%)]\tLoss:0.095690\n",
      "train epoch: 8 [12160/60000 (20%)]\tLoss:0.091515\n",
      "train epoch: 8 [12800/60000 (21%)]\tLoss:0.105174\n",
      "train epoch: 8 [13440/60000 (22%)]\tLoss:0.118619\n",
      "train epoch: 8 [14080/60000 (23%)]\tLoss:0.117457\n",
      "train epoch: 8 [14720/60000 (25%)]\tLoss:0.054262\n",
      "train epoch: 8 [15360/60000 (26%)]\tLoss:0.072397\n",
      "train epoch: 8 [16000/60000 (27%)]\tLoss:0.068151\n",
      "train epoch: 8 [16640/60000 (28%)]\tLoss:0.113479\n",
      "train epoch: 8 [17280/60000 (29%)]\tLoss:0.054059\n",
      "train epoch: 8 [17920/60000 (30%)]\tLoss:0.042933\n",
      "train epoch: 8 [18560/60000 (31%)]\tLoss:0.339779\n",
      "train epoch: 8 [19200/60000 (32%)]\tLoss:0.033359\n",
      "train epoch: 8 [19840/60000 (33%)]\tLoss:0.126044\n",
      "train epoch: 8 [20480/60000 (34%)]\tLoss:0.100815\n",
      "train epoch: 8 [21120/60000 (35%)]\tLoss:0.118912\n",
      "train epoch: 8 [21760/60000 (36%)]\tLoss:0.271238\n",
      "train epoch: 8 [22400/60000 (37%)]\tLoss:0.051229\n",
      "train epoch: 8 [23040/60000 (38%)]\tLoss:0.077098\n",
      "train epoch: 8 [23680/60000 (39%)]\tLoss:0.117200\n",
      "train epoch: 8 [24320/60000 (41%)]\tLoss:0.042018\n",
      "train epoch: 8 [24960/60000 (42%)]\tLoss:0.060142\n",
      "train epoch: 8 [25600/60000 (43%)]\tLoss:0.160560\n",
      "train epoch: 8 [26240/60000 (44%)]\tLoss:0.084246\n",
      "train epoch: 8 [26880/60000 (45%)]\tLoss:0.119314\n",
      "train epoch: 8 [27520/60000 (46%)]\tLoss:0.138266\n",
      "train epoch: 8 [28160/60000 (47%)]\tLoss:0.093259\n",
      "train epoch: 8 [28800/60000 (48%)]\tLoss:0.110516\n",
      "train epoch: 8 [29440/60000 (49%)]\tLoss:0.072039\n",
      "train epoch: 8 [30080/60000 (50%)]\tLoss:0.146560\n",
      "train epoch: 8 [30720/60000 (51%)]\tLoss:0.128981\n",
      "train epoch: 8 [31360/60000 (52%)]\tLoss:0.131735\n",
      "train epoch: 8 [32000/60000 (53%)]\tLoss:0.084281\n",
      "train epoch: 8 [32640/60000 (54%)]\tLoss:0.029406\n",
      "train epoch: 8 [33280/60000 (55%)]\tLoss:0.189311\n",
      "train epoch: 8 [33920/60000 (57%)]\tLoss:0.142425\n",
      "train epoch: 8 [34560/60000 (58%)]\tLoss:0.064508\n",
      "train epoch: 8 [35200/60000 (59%)]\tLoss:0.162953\n",
      "train epoch: 8 [35840/60000 (60%)]\tLoss:0.091682\n",
      "train epoch: 8 [36480/60000 (61%)]\tLoss:0.151661\n",
      "train epoch: 8 [37120/60000 (62%)]\tLoss:0.168636\n",
      "train epoch: 8 [37760/60000 (63%)]\tLoss:0.048446\n",
      "train epoch: 8 [38400/60000 (64%)]\tLoss:0.124871\n",
      "train epoch: 8 [39040/60000 (65%)]\tLoss:0.102310\n",
      "train epoch: 8 [39680/60000 (66%)]\tLoss:0.144626\n",
      "train epoch: 8 [40320/60000 (67%)]\tLoss:0.102103\n",
      "train epoch: 8 [40960/60000 (68%)]\tLoss:0.091905\n",
      "train epoch: 8 [41600/60000 (69%)]\tLoss:0.234601\n",
      "train epoch: 8 [42240/60000 (70%)]\tLoss:0.102962\n",
      "train epoch: 8 [42880/60000 (71%)]\tLoss:0.189875\n",
      "train epoch: 8 [43520/60000 (72%)]\tLoss:0.228458\n",
      "train epoch: 8 [44160/60000 (74%)]\tLoss:0.219959\n",
      "train epoch: 8 [44800/60000 (75%)]\tLoss:0.191288\n",
      "train epoch: 8 [45440/60000 (76%)]\tLoss:0.156869\n",
      "train epoch: 8 [46080/60000 (77%)]\tLoss:0.064547\n",
      "train epoch: 8 [46720/60000 (78%)]\tLoss:0.052765\n",
      "train epoch: 8 [47360/60000 (79%)]\tLoss:0.124705\n",
      "train epoch: 8 [48000/60000 (80%)]\tLoss:0.137943\n",
      "train epoch: 8 [48640/60000 (81%)]\tLoss:0.094068\n",
      "train epoch: 8 [49280/60000 (82%)]\tLoss:0.171933\n",
      "train epoch: 8 [49920/60000 (83%)]\tLoss:0.059033\n",
      "train epoch: 8 [50560/60000 (84%)]\tLoss:0.089037\n",
      "train epoch: 8 [51200/60000 (85%)]\tLoss:0.230053\n",
      "train epoch: 8 [51840/60000 (86%)]\tLoss:0.038289\n",
      "train epoch: 8 [52480/60000 (87%)]\tLoss:0.083966\n",
      "train epoch: 8 [53120/60000 (88%)]\tLoss:0.348147\n",
      "train epoch: 8 [53760/60000 (90%)]\tLoss:0.122508\n",
      "train epoch: 8 [54400/60000 (91%)]\tLoss:0.143917\n",
      "train epoch: 8 [55040/60000 (92%)]\tLoss:0.127288\n",
      "train epoch: 8 [55680/60000 (93%)]\tLoss:0.120339\n",
      "train epoch: 8 [56320/60000 (94%)]\tLoss:0.115644\n",
      "train epoch: 8 [56960/60000 (95%)]\tLoss:0.038209\n",
      "train epoch: 8 [57600/60000 (96%)]\tLoss:0.115670\n",
      "train epoch: 8 [58240/60000 (97%)]\tLoss:0.074666\n",
      "train epoch: 8 [58880/60000 (98%)]\tLoss:0.034760\n",
      "train epoch: 8 [59520/60000 (99%)]\tLoss:0.085645\n",
      "\n",
      "test set: Average loss: 0.0018, accuracy: 9665/10000 (97%)\n",
      "\n",
      "train epoch: 9 [0/60000 (0%)]\tLoss:0.181761\n",
      "train epoch: 9 [640/60000 (1%)]\tLoss:0.085126\n",
      "train epoch: 9 [1280/60000 (2%)]\tLoss:0.150295\n",
      "train epoch: 9 [1920/60000 (3%)]\tLoss:0.066702\n",
      "train epoch: 9 [2560/60000 (4%)]\tLoss:0.178588\n",
      "train epoch: 9 [3200/60000 (5%)]\tLoss:0.090868\n",
      "train epoch: 9 [3840/60000 (6%)]\tLoss:0.042228\n",
      "train epoch: 9 [4480/60000 (7%)]\tLoss:0.110579\n",
      "train epoch: 9 [5120/60000 (9%)]\tLoss:0.257766\n",
      "train epoch: 9 [5760/60000 (10%)]\tLoss:0.093030\n",
      "train epoch: 9 [6400/60000 (11%)]\tLoss:0.093641\n",
      "train epoch: 9 [7040/60000 (12%)]\tLoss:0.132424\n",
      "train epoch: 9 [7680/60000 (13%)]\tLoss:0.078140\n",
      "train epoch: 9 [8320/60000 (14%)]\tLoss:0.118085\n",
      "train epoch: 9 [8960/60000 (15%)]\tLoss:0.132318\n",
      "train epoch: 9 [9600/60000 (16%)]\tLoss:0.046238\n",
      "train epoch: 9 [10240/60000 (17%)]\tLoss:0.101559\n",
      "train epoch: 9 [10880/60000 (18%)]\tLoss:0.042842\n",
      "train epoch: 9 [11520/60000 (19%)]\tLoss:0.051801\n",
      "train epoch: 9 [12160/60000 (20%)]\tLoss:0.101601\n",
      "train epoch: 9 [12800/60000 (21%)]\tLoss:0.110003\n",
      "train epoch: 9 [13440/60000 (22%)]\tLoss:0.110628\n",
      "train epoch: 9 [14080/60000 (23%)]\tLoss:0.130113\n",
      "train epoch: 9 [14720/60000 (25%)]\tLoss:0.113581\n",
      "train epoch: 9 [15360/60000 (26%)]\tLoss:0.058164\n",
      "train epoch: 9 [16000/60000 (27%)]\tLoss:0.161544\n",
      "train epoch: 9 [16640/60000 (28%)]\tLoss:0.099930\n",
      "train epoch: 9 [17280/60000 (29%)]\tLoss:0.152203\n",
      "train epoch: 9 [17920/60000 (30%)]\tLoss:0.163092\n",
      "train epoch: 9 [18560/60000 (31%)]\tLoss:0.036813\n",
      "train epoch: 9 [19200/60000 (32%)]\tLoss:0.128449\n",
      "train epoch: 9 [19840/60000 (33%)]\tLoss:0.122676\n",
      "train epoch: 9 [20480/60000 (34%)]\tLoss:0.048513\n",
      "train epoch: 9 [21120/60000 (35%)]\tLoss:0.080735\n",
      "train epoch: 9 [21760/60000 (36%)]\tLoss:0.289427\n",
      "train epoch: 9 [22400/60000 (37%)]\tLoss:0.216488\n",
      "train epoch: 9 [23040/60000 (38%)]\tLoss:0.064715\n",
      "train epoch: 9 [23680/60000 (39%)]\tLoss:0.040974\n",
      "train epoch: 9 [24320/60000 (41%)]\tLoss:0.054831\n",
      "train epoch: 9 [24960/60000 (42%)]\tLoss:0.051808\n",
      "train epoch: 9 [25600/60000 (43%)]\tLoss:0.124564\n",
      "train epoch: 9 [26240/60000 (44%)]\tLoss:0.032453\n",
      "train epoch: 9 [26880/60000 (45%)]\tLoss:0.016735\n",
      "train epoch: 9 [27520/60000 (46%)]\tLoss:0.049568\n",
      "train epoch: 9 [28160/60000 (47%)]\tLoss:0.048309\n",
      "train epoch: 9 [28800/60000 (48%)]\tLoss:0.079264\n",
      "train epoch: 9 [29440/60000 (49%)]\tLoss:0.081407\n",
      "train epoch: 9 [30080/60000 (50%)]\tLoss:0.076234\n",
      "train epoch: 9 [30720/60000 (51%)]\tLoss:0.072386\n",
      "train epoch: 9 [31360/60000 (52%)]\tLoss:0.163441\n",
      "train epoch: 9 [32000/60000 (53%)]\tLoss:0.025951\n",
      "train epoch: 9 [32640/60000 (54%)]\tLoss:0.145025\n",
      "train epoch: 9 [33280/60000 (55%)]\tLoss:0.076468\n",
      "train epoch: 9 [33920/60000 (57%)]\tLoss:0.056927\n",
      "train epoch: 9 [34560/60000 (58%)]\tLoss:0.058233\n",
      "train epoch: 9 [35200/60000 (59%)]\tLoss:0.081623\n",
      "train epoch: 9 [35840/60000 (60%)]\tLoss:0.048236\n",
      "train epoch: 9 [36480/60000 (61%)]\tLoss:0.061732\n",
      "train epoch: 9 [37120/60000 (62%)]\tLoss:0.162608\n",
      "train epoch: 9 [37760/60000 (63%)]\tLoss:0.070060\n",
      "train epoch: 9 [38400/60000 (64%)]\tLoss:0.027035\n",
      "train epoch: 9 [39040/60000 (65%)]\tLoss:0.063379\n",
      "train epoch: 9 [39680/60000 (66%)]\tLoss:0.101695\n",
      "train epoch: 9 [40320/60000 (67%)]\tLoss:0.064139\n",
      "train epoch: 9 [40960/60000 (68%)]\tLoss:0.071135\n",
      "train epoch: 9 [41600/60000 (69%)]\tLoss:0.116553\n",
      "train epoch: 9 [42240/60000 (70%)]\tLoss:0.131162\n",
      "train epoch: 9 [42880/60000 (71%)]\tLoss:0.201668\n",
      "train epoch: 9 [43520/60000 (72%)]\tLoss:0.122683\n",
      "train epoch: 9 [44160/60000 (74%)]\tLoss:0.056237\n",
      "train epoch: 9 [44800/60000 (75%)]\tLoss:0.184924\n",
      "train epoch: 9 [45440/60000 (76%)]\tLoss:0.031474\n",
      "train epoch: 9 [46080/60000 (77%)]\tLoss:0.203619\n",
      "train epoch: 9 [46720/60000 (78%)]\tLoss:0.098342\n",
      "train epoch: 9 [47360/60000 (79%)]\tLoss:0.117824\n",
      "train epoch: 9 [48000/60000 (80%)]\tLoss:0.218499\n",
      "train epoch: 9 [48640/60000 (81%)]\tLoss:0.118220\n",
      "train epoch: 9 [49280/60000 (82%)]\tLoss:0.134972\n",
      "train epoch: 9 [49920/60000 (83%)]\tLoss:0.091221\n",
      "train epoch: 9 [50560/60000 (84%)]\tLoss:0.091709\n",
      "train epoch: 9 [51200/60000 (85%)]\tLoss:0.142610\n",
      "train epoch: 9 [51840/60000 (86%)]\tLoss:0.034177\n",
      "train epoch: 9 [52480/60000 (87%)]\tLoss:0.238003\n",
      "train epoch: 9 [53120/60000 (88%)]\tLoss:0.070285\n",
      "train epoch: 9 [53760/60000 (90%)]\tLoss:0.037864\n",
      "train epoch: 9 [54400/60000 (91%)]\tLoss:0.092097\n",
      "train epoch: 9 [55040/60000 (92%)]\tLoss:0.061455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 9 [55680/60000 (93%)]\tLoss:0.120998\n",
      "train epoch: 9 [56320/60000 (94%)]\tLoss:0.168595\n",
      "train epoch: 9 [56960/60000 (95%)]\tLoss:0.050291\n",
      "train epoch: 9 [57600/60000 (96%)]\tLoss:0.272128\n",
      "train epoch: 9 [58240/60000 (97%)]\tLoss:0.096658\n",
      "train epoch: 9 [58880/60000 (98%)]\tLoss:0.104032\n",
      "train epoch: 9 [59520/60000 (99%)]\tLoss:0.091484\n",
      "\n",
      "test set: Average loss: 0.0017, accuracy: 9682/10000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
